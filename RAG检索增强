RAG检索增强

某些情况下，模型无法提供准确的答案，RAG应运而生，该架构整合了从大型知识库中检索到的相关信息，并以此为基础，指导大语言模型生成更准确的答案。

LLM主要面临的问题：信息偏差/幻觉、知识更新落后、内容不可追溯、专业知识欠缺、推理能力不足、应用场景受限、长文本处理较弱。

RAG是一个系统，简单的可分为数据处理、检索、增强、生成四个阶段。原始数据清理后，调用embedding模型计算embedding值，存入向量数据库（构建以及模型选择，可参考Halukisan/ModelDataBase: Es和向量数据库Milvus的构建与数据存储 (github.com)），然后将用户的问题输入到检索系统中，从数据库中检索相关信息，增强阶段：对检索的信息进行处理和增强。

对于模型训练，RAG和微调是两种主流方式

RAG可以更新检索知识库，无需重新训练，适合动态变化的数据，但模型的风格不好充分的自定义，推理时间也会变长，但可以有效的降低模型产生幻觉的概率，在使用RAG引用外部数据时，需要考虑隐私版权问题。
